# ğŸ§  LLaDA-CoT: Semi-Autoregressive Reasoning with LLaDA

ì´ í”„ë¡œì íŠ¸ëŠ” [`GSAI-ML/LLaDA-8B-Instruct`](https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct) ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ, **Step-by-step Chain-of-Thought(CoT) ì¶”ë¡ **ì„ ë°˜ì˜í•œ ì„¸ë¯¸ ì˜¤í† ë¦¬ê·¸ë ˆì‹œë¸Œ ë°©ì‹ì˜ ë¬¸ì œ í•´ê²° ë°©ì‹ì„ êµ¬í˜„í•œ ê²ƒì…ë‹ˆë‹¤.

> Masked Denoising ë°©ì‹ê³¼ LoRA ê¸°ë°˜ ë¯¸ì„¸ì¡°ì •ì„ í†µí•´ LLaDA ëª¨ë¸ì˜ ìˆ˜í•™ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
.
â”œâ”€â”€ generate.py             # ì„¸ë¯¸ ì˜¤í† ë¦¬ê·¸ë ˆì‹œë¸Œ ë°©ì‹ ìƒì„± í•¨ìˆ˜
â”œâ”€â”€ train.py                # LoRA ê¸°ë°˜ í•™ìŠµ ì½”ë“œ
â”œâ”€â”€ solve.py                # ì •ë‹µ ì¶”ì¶œ ë° ì¶”ë¡  í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt        # ì‹¤í–‰ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ modelss/                # í•™ìŠµëœ adapter(LORA) ì €ì¥ ê²½ë¡œ
â””â”€â”€ datasets/
    â”œâ”€â”€ train.jsonl         # í•™ìŠµìš© jsonl íŒŒì¼
    â””â”€â”€ test.jsonl          # í‰ê°€ìš© jsonl íŒŒì¼
```

---

## ğŸš€ ì„¤ì¹˜ ë° ì‹¤í–‰ ë°©ë²•

### 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

> âœ… `torch`, `transformers`, `peft`, `tqdm` ë“±ì´ í•„ìš”í•©ë‹ˆë‹¤.

### 2. í•™ìŠµ ì‹¤í–‰

```bash
python train.py
```

- í•™ìŠµ ë°ì´í„°: `datasets/train.jsonl`
- í•™ìŠµ ê²°ê³¼: `modelss/llada_multi_pass_epoch*` ì— ì €ì¥ë©ë‹ˆë‹¤.

### 3. ì¶”ë¡  ì‹¤í–‰

```bash
python solve.py
```

- ì…ë ¥: `datasets/test.jsonl`
- ê²°ê³¼: `infer_outputsss1.jsonl` (ì •ë‹µ/ì˜ˆì¸¡/ì¶œë ¥ í¬í•¨)

---

## âš™ï¸ ì£¼ìš” êµ¬ì„±

### `generate.py`

- Semi-autoregressive masked generation êµ¬í˜„
- `generate(...)` í•¨ìˆ˜ëŠ” `block_length` ë‹¨ìœ„ë¡œ ë§ˆìŠ¤í¬ëœ ì˜ì—­ì„ ì ì§„ì ìœ¼ë¡œ ì±„ì›€
- Gumbel noise ë° classifier-free guidance ê¸°ëŠ¥ í¬í•¨

### `train.py`

- LoRA ê¸°ë°˜ Masked Denoising í•™ìŠµ ë£¨í”„
- Chain-of-Thought ë°ì´í„°ë¥¼ í† ë§‰ë‚´ì–´ step-by-stepìœ¼ë¡œ ëª¨ë¸ì— í•™ìŠµ

### `solve.py`

- í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ `\boxed{...}` í¬ë§·ì˜ ë‹µ ì¶”ì¶œ
- ì •í™•ë„ í‰ê°€ ë° JSONL ì €ì¥

---

## ğŸ“Š ì˜ˆì‹œ ê²°ê³¼ (output JSONL)

```json
{
  "prompt": "What is 25 Ã— 4?",
  "gold_answer": "100",
  "model_answer": "100",
  "raw_output": "To calculate 25 Ã— 4, we multiply the numbers: 25 Ã— 4 = \boxed{100}",
  "correct": true
}
```

---

## ğŸ“ ë°ì´í„° í˜•ì‹

### í•™ìŠµ ë°ì´í„° (`train.jsonl`)

```json
{
  "prompt": "Solve 3 + 4",
  "rationales": ["3 + 4 = 7"],
  "answer": "\boxed{7}"
}
```

### í…ŒìŠ¤íŠ¸ ë°ì´í„° (`test.jsonl`)

```json
{
  "prompt": "What is 15 Ã— 2?",
  "answer": "30"
}
```

---

## ğŸ’¡ í–¥í›„ ê°œì„  ì•„ì´ë””ì–´

- ë‘ ë‹¨ê³„ ìƒì„±: `rationale` ìƒì„± í›„ `ìˆ«ì/boxed` ì±„ìš°ëŠ” ë°©ì‹ ì ìš©
- mask token ìœ„ì¹˜ ê¸°ë°˜ fine-tuned generation
- í‰ê°€ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ prompt-tuning ë° rational sampling ì „ëµ

---

## ğŸ“œ ë¼ì´ì„ ìŠ¤

MIT License

---

## ğŸ™ ì°¸ê³ 

- [LLaDA Paper](https://arxiv.org/abs/2402.10303)
- [HuggingFace Transformers](https://github.com/huggingface/transformers)
- [PEFT (LoRA)](https://github.com/huggingface/peft)
